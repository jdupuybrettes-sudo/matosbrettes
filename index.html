import React, { useCallback, useEffect, useMemo, useRef, useState } from "react";
import {
  AlertCircle,
  Loader2,
  RefreshCw,
  Image as ImageIcon,
  Edit2,
  Check,
  Zap,
  Sparkles,
  Flashlight,
  FlashlightOff,
  ZoomIn
} from "lucide-react";

import { BrowserMultiFormatReader } from "@zxing/browser";
import {
  BarcodeFormat,
  BinaryBitmap,
  DecodeHintType,
  HybridBinarizer,
  MultiFormatReader,
  NotFoundException,
  RGBLuminanceSource,
} from "@zxing/library";

import { extractIdFromTag } from "../services/geminiService";

type QRScannerProps = {
  onResult: (value: string) => void;
};

type TrackCaps = Partial<MediaTrackCapabilities> & {
  torch?: boolean;
  zoom?: number;
};

function normalizeResult(v: string) {
  const raw = (v ?? "").trim();
  // Nettoyage pour tes étiquettes chiffres (ex: "454 844 738" -> "454844738")
  const digitsOnly = raw.replace(/[^\d]/g, "");
  if (digitsOnly.length === 9) return digitsOnly;
  return raw;
}

const QRScanner: React.FC<QRScannerProps> = ({ onResult }) => {
  const [manualCode, setManualCode] = useState("");
  const [isCameraActive, setIsCameraActive] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);

  const [torchOn, setTorchOn] = useState(false);
  const [supportsTorch, setSupportsTorch] = useState(false);

  const [supportsZoom, setSupportsZoom] = useState(false);
  const [zoom, setZoom] = useState(1);
  const zoomMinRef = useRef(1);
  const zoomMaxRef = useRef(1);

  const videoRef = useRef<HTMLVideoElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const streamRef = useRef<MediaStream | null>(null);
  const trackRef = useRef<MediaStreamTrack | null>(null);

  const stoppedRef = useRef(false);
  const hasScannedRef = useRef(false);
  const scanTimerRef = useRef<number | null>(null);
  const startingRef = useRef(false);

  // Canvas offscreen (scan)
  const scanCanvasRef = useRef<HTMLCanvasElement | null>(null);
  if (!scanCanvasRef.current && typeof document !== "undefined") {
    scanCanvasRef.current = document.createElement("canvas");
  }

  // ZXing: lecteur robuste “try harder”
  const zxingReader = useMemo(() => {
    const reader = new MultiFormatReader();
    const hints = new Map();
    hints.set(DecodeHintType.TRY_HARDER, true);
    hints.set(DecodeHintType.ALSO_INVERTED, true);
    hints.set(DecodeHintType.POSSIBLE_FORMATS, [
      BarcodeFormat.DATA_MATRIX,
      BarcodeFormat.QR_CODE,
      BarcodeFormat.CODE_128,
      BarcodeFormat.CODE_39,
      BarcodeFormat.EAN_13,
      BarcodeFormat.EAN_8,
    ]);
    reader.setHints(hints);
    return reader;
  }, []);

  // (Optionnel) ZXing browser (parfois utile, mais on l’utilise surtout en secours)
  const browserReader = useMemo(() => new BrowserMultiFormatReader(), []);

  const notifyResult = useCallback(
    (value: string) => {
      const cleaned = normalizeResult(value);
      onResult(cleaned);
      // (Optionnel) tu peux aussi copier automatiquement :
      // navigator.clipboard?.writeText(cleaned).catch(() => {});
    },
    [onResult]
  );

  const stopScanner = useCallback(() => {
    stoppedRef.current = true;
    startingRef.current = false;

    if (scanTimerRef.current) {
      window.clearTimeout(scanTimerRef.current);
      scanTimerRef.current = null;
    }

    try {
      browserReader?.reset?.();
    } catch {}

    if (trackRef.current) {
      try {
        trackRef.current.stop();
      } catch {}
      trackRef.current = null;
    }

    if (streamRef.current) {
      try {
        streamRef.current.getTracks().forEach((t) => t.stop());
      } catch {}
      streamRef.current = null;
    }

    const video = videoRef.current;
    if (video) video.srcObject = null;

    setIsCameraActive(false);
  }, [browserReader]);

  const applyTorch = useCallback(async (on: boolean) => {
    const track = trackRef.current;
    if (!track) return;

    // Certains navigateurs n’acceptent torch que via advanced constraints
    try {
      // @ts-ignore
      await track.applyConstraints({ advanced: [{ torch: on }] });
      setTorchOn(on);
    } catch {
      // silencieux
      setTorchOn(false);
    }
  }, []);

  const applyZoom = useCallback(async (z: number) => {
    const track = trackRef.current;
    if (!track) return;

    const clamped = Math.max(zoomMinRef.current, Math.min(zoomMaxRef.current, z));
    try {
      // @ts-ignore
      await track.applyConstraints({ advanced: [{ zoom: clamped }] });
      setZoom(clamped);
    } catch {
      // silencieux
    }
  }, []);

  const decodeWithNativeDetector = useCallback(async (source: CanvasImageSource) => {
    // @ts-ignore
    if (!("BarcodeDetector" in window)) return null;
    try {
      // @ts-ignore
      const detector = new window.BarcodeDetector({
        formats: ["data_matrix", "qr_code", "code_128", "code_39", "ean_13", "ean_8"]
      });
      const codes = await detector.detect(source);
      return codes?.[0]?.rawValue ?? null;
    } catch {
      return null;
    }
  }, []);

  const decodeWithZXingFromCanvas = useCallback(async (canvas: HTMLCanvasElement) => {
    try {
      const ctx = canvas.getContext("2d", { willReadFrequently: true });
      if (!ctx) return null;
      const { width, height } = canvas;
      const imgData = ctx.getImageData(0, 0, width, height);

      // Luminance source + binarizer
      const luminance = new RGBLuminanceSource(imgData.data, width, height);
      const bitmap = new BinaryBitmap(new HybridBinarizer(luminance));

      const res = zxingReader.decode(bitmap);
      zxingReader.reset();
      return res?.getText?.() ?? null;
    } catch (e: any) {
      try {
        zxingReader.reset();
      } catch {}
      if (e instanceof NotFoundException) return null;
      return null;
    }
  }, [zxingReader]);

  const drawCropped = useCallback((video: HTMLVideoElement, crop: {x:number;y:number;w:number;h:number}, filter?: string) => {
    const canvas = scanCanvasRef.current!;
    const ctx = canvas.getContext("2d", { willReadFrequently: true });
    if (!ctx) return null;

    // On réduit un peu la taille pour accélérer le decode (tout en gardant assez de détail)
    const targetW = 900;
    const scale = targetW / crop.w;
    const targetH = Math.round(crop.h * scale);

    canvas.width = targetW;
    canvas.height = targetH;

    ctx.save();
    // filtres anti-reflets / contraste
    if (filter) ctx.filter = filter;
    ctx.drawImage(video, crop.x, crop.y, crop.w, crop.h, 0, 0, targetW, targetH);
    ctx.restore();

    return canvas;
  }, []);

  const startScanner = useCallback(async () => {
    if (startingRef.current) return;
    startingRef.current = true;

    setError(null);
    stoppedRef.current = false;
    hasScannedRef.current = false;

    stopScanner();

    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: { ideal: "environment" },
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          frameRate: { ideal: 30, max: 60 },
        },
        audio: false,
      });

      streamRef.current = stream;
      const track = stream.getVideoTracks()[0];
      trackRef.current = track;

      // Capacités (torch/zoom) si dispo
      const caps = (track.getCapabilities?.() ?? {}) as TrackCaps;

      setSupportsTorch(!!caps.torch);
      setSupportsZoom(typeof caps.zoom === "number" || (caps as any).zoom?.max);

      // Zoom min/max si exposés
      const zoomCaps = (caps as any).zoom;
      if (zoomCaps?.min && zoomCaps?.max) {
        zoomMinRef.current = zoomCaps.min;
        zoomMaxRef.current = zoomCaps.max;
        setZoom(zoomCaps.min);
      } else {
        zoomMinRef.current = 1;
        zoomMaxRef.current = 1;
        setZoom(1);
      }

      // Tentatives autofocus/expo (selon support)
      try {
        const advanced: any[] = [];
        if ((navigator as any).mediaDevices?.getSupportedConstraints?.().focusMode) {
          advanced.push({ focusMode: "continuous" });
        }
        if ((navigator as any).mediaDevices?.getSupportedConstraints?.().exposureMode) {
          advanced.push({ exposureMode: "continuous" });
        }
        if (advanced.length) {
          await track.applyConstraints({ advanced });
        }
      } catch {
        // ok si non supporté
      }

      // Branche la vidéo
      const video = videoRef.current;
      if (!video) throw new Error("video element missing");
      video.srcObject = stream;
      await video.play();
      setIsCameraActive(true);

      // Boucle scan (crop + multi-essais)
      const tick = async () => {
        if (stoppedRef.current || hasScannedRef.current) return;

        const v = videoRef.current;
        if (!v || v.readyState < 2) {
          scanTimerRef.current = window.setTimeout(tick, 150);
          return;
        }

        const vw = v.videoWidth;
        const vh = v.videoHeight;
        if (!vw || !vh) {
          scanTimerRef.current = window.setTimeout(tick, 150);
          return;
        }

        // Crops (on teste plusieurs tailles : utile quand l’étiquette n’est pas parfaitement centrée)
        const crops = [
          { w: vw * 0.70, h: vh * 0.42 },
          { w: vw * 0.85, h: vh * 0.55 },
          { w: vw * 0.55, h: vh * 0.35 },
        ].map(({ w, h }) => ({
          x: (vw - w) / 2,
          y: (vh - h) / 2,
          w,
          h,
        }));

        // Filtres successifs (anti reflets / contraste)
        const filters = [
          undefined,
          "grayscale(1) contrast(1.35)",
          "grayscale(1) contrast(1.55) brightness(1.05)",
        ];

        for (const crop of crops) {
          for (const filter of filters) {
            const canvas = drawCropped(v, crop, filter);
            if (!canvas) continue;

            // 1) BarcodeDetector (rapide quand dispo)
            const nativeText = await decodeWithNativeDetector(canvas);
            if (nativeText) {
              hasScannedRef.current = true;
              stopScanner();
              notifyResult(nativeText);
              return;
            }

            // 2) ZXing “try harder”
            const zxingText = await decodeWithZXingFromCanvas(canvas);
            if (zxingText) {
              hasScannedRef.current = true;
              stopScanner();
              notifyResult(zxingText);
              return;
            }
          }
        }

        scanTimerRef.current = window.setTimeout(tick, 120);
      };

      tick();
    } catch (err: any) {
      setError("Accès caméra impossible. Vérifiez les permissions (HTTPS obligatoire).");
      setIsCameraActive(false);
    } finally {
      startingRef.current = false;
    }
  }, [
    stopScanner,
    notifyResult,
    decodeWithNativeDetector,
    decodeWithZXingFromCanvas,
    drawCropped
  ]);

  useEffect(() => {
    startScanner();
    return () => stopScanner();
  }, [startScanner, stopScanner]);

  const handleAIScan = async () => {
    if (!videoRef.current || isAnalyzing) return;
    setIsAnalyzing(true);
    setError(null);

    try {
      const video = videoRef.current;
      const vw = video.videoWidth;
      const vh = video.videoHeight;
      if (!vw || !vh) throw new Error("video not ready");

      // Capture sur zone centrale “étiquette”
      const crop = {
        x: vw * 0.15,
        y: vh * 0.30,
        w: vw * 0.70,
        h: vh * 0.40,
      };

      const canvas = document.createElement("canvas");
      const targetW = 1400;
      const scale = targetW / crop.w;
      canvas.width = targetW;
      canvas.height = Math.round(crop.h * scale);

      const ctx = canvas.getContext("2d");
      if (!ctx) throw new Error("Canvas context error");

      // Un petit boost contraste pour l’OCR
      ctx.filter = "grayscale(1) contrast(1.5) brightness(1.05)";
      ctx.drawImage(video, crop.x, crop.y, crop.w, crop.h, 0, 0, canvas.width, canvas.height);

      const base64 = canvas.toDataURL("image/jpeg", 0.9).split(",")[1];
      const result = await extractIdFromTag(base64);

      if (result) {
        hasScannedRef.current = true;
        stopScanner();
        notifyResult(result);
      } else {
        setError("L'IA n'a pas pu lire. Mets l'étiquette à l’ombre + incline légèrement.");
      }
    } catch {
      setError("Erreur d'identification intelligente.");
    } finally {
      setIsAnalyzing(false);
    }
  };

  const handleManualSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    const v = manualCode.trim();
    if (v) {
      notifyResult(v);
      setManualCode("");
    }
  };

  return (
    <div className="flex flex-col items-center gap-5 w-full">
      <div className="relative w-full aspect-square bg-slate-950 rounded-[2.5rem] overflow-hidden shadow-2xl border-4 border-slate-100">
        <video ref={videoRef} autoPlay playsInline muted className="w-full h-full object-cover" />

        {!isCameraActive && (
          <div className="absolute inset-0 flex flex-col items-center justify-center text-slate-700 p-8 text-center bg-slate-900 z-10">
            {error ? (
              <AlertCircle size={48} className="text-amber-500 mb-4" />
            ) : (
              <Loader2 size={48} className="animate-spin mb-4 text-blue-500" />
            )}
            <p className="text-[12px] font-black uppercase tracking-widest text-slate-300 mb-8 px-6 leading-relaxed">
              {error || "Préparation de la caméra..."}
            </p>
            <button
              onClick={startScanner}
              className="px-10 py-5 bg-white text-slate-900 rounded-2xl font-black text-[11px] uppercase tracking-widest shadow-2xl flex items-center gap-3"
            >
              <RefreshCw size={18} /> Réessayer
            </button>
          </div>
        )}

        {isCameraActive && (
          <>
            {/* Viseur */}
            <div className="absolute inset-0 pointer-events-none flex items-center justify-center">
              <div className="relative w-64 h-48 border-2 border-white/20 rounded-3xl bg-black/5">
                <div className="absolute -top-1 -left-1 w-10 h-10 border-t-4 border-l-4 border-blue-500 rounded-tl-xl"></div>
                <div className="absolute -top-1 -right-1 w-10 h-10 border-t-4 border-r-4 border-blue-500 rounded-tr-xl"></div>
                <div className="absolute -bottom-1 -left-1 w-10 h-10 border-b-4 border-l-4 border-blue-500 rounded-bl-xl"></div>
                <div className="absolute -bottom-1 -right-1 w-10 h-10 border-b-4 border-r-4 border-blue-500 rounded-br-xl"></div>
              </div>
            </div>

            {/* Controls overlay */}
            <div className="absolute top-4 left-4 right-4 flex items-center justify-between z-20">
              <div className="flex gap-2">
                {supportsTorch && (
                  <button
                    onClick={() => applyTorch(!torchOn)}
                    className="pointer-events-auto px-4 py-3 bg-white/90 rounded-2xl font-black text-[10px] uppercase tracking-widest flex items-center gap-2"
                    title="Lampe"
                  >
                    {torchOn ? <FlashlightOff size={16} /> : <Flashlight size={16} />}
                    Lampe
                  </button>
                )}
              </div>

              {supportsZoom && zoomMaxRef.current > zoomMinRef.current && (
                <div className="pointer-events-auto flex items-center gap-2 bg-white/90 rounded-2xl px-4 py-3">
                  <ZoomIn size={16} />
                  <input
                    type="range"
                    min={zoomMinRef.current}
                    max={zoomMaxRef.current}
                    step={0.1}
                    value={zoom}
                    onChange={(e) => applyZoom(parseFloat(e.target.value))}
                  />
                </div>
              )}
            </div>
          </>
        )}

        {isAnalyzing && (
          <div className="absolute inset-0 bg-blue-900/80 backdrop-blur-md flex flex-col items-center justify-center z-50">
            <Loader2 className="text-white animate-spin" size={48} />
            <p className="mt-4 text-[10px] text-white font-black uppercase tracking-[0.2em] flex items-center gap-2">
              <Sparkles size={14} className="text-blue-300" /> Analyse intelligente...
            </p>
          </div>
        )}
      </div>

      <div className="w-full space-y-4">
        <button
          onClick={handleAIScan}
          disabled={!isCameraActive || isAnalyzing}
          className="w-full py-6 bg-slate-900 text-white rounded-[2rem] font-black text-xs uppercase tracking-[0.15em] flex items-center justify-center gap-3 shadow-2xl hover:bg-black transition-all active:scale-95 disabled:opacity-50"
        >
          <Zap size={20} className="text-blue-400 fill-blue-400" />
          Récupérer les chiffres (IA)
        </button>

        <div className="grid grid-cols-2 gap-3">
          <button
            onClick={() => fileInputRef.current?.click()}
            className="py-5 px-4 bg-slate-100 text-slate-600 rounded-2xl font-black text-[10px] uppercase tracking-widest flex items-center justify-center gap-3"
          >
            <ImageIcon size={18} /> Galerie
          </button>
          <button
            onClick={() => setManualCode(manualCode === "" ? " " : "")}
            className="py-5 px-4 bg-slate-100 text-slate-600 rounded-2xl font-black text-[10px] uppercase tracking-widest flex items-center justify-center gap-3"
          >
            <Edit2 size={18} /> Manuel
          </button>
        </div>

        <input
          ref={fileInputRef}
          type="file"
          accept="image/*"
          className="hidden"
          onChange={async (e) => {
            const file = e.target.files?.[0];
            if (!file) return;
            setIsAnalyzing(true);
            setError(null);
            try {
              const reader = new FileReader();
              reader.onload = async (ev) => {
                try {
                  const b64 = (ev.target?.result as string).split(",")[1];
                  const res = await extractIdFromTag(b64);
                  if (res) notifyResult(res);
                  else setError("Impossible de lire l'étiquette sur cette photo.");
                } finally {
                  setIsAnalyzing(false);
                }
              };
              reader.readAsDataURL(file);
            } catch {
              setIsAnalyzing(false);
            }
          }}
        />

        {manualCode !== "" && (
          <form onSubmit={handleManualSubmit} className="flex gap-2 animate-in slide-in-from-bottom-2">
            <input
              type="text"
              autoFocus
              value={manualCode === " " ? "" : manualCode}
              onChange={(e) => setManualCode(e.target.value)}
              placeholder="Ex: 454 844 738"
              className="flex-1 px-6 py-4 bg-white border-2 border-slate-100 rounded-2xl font-bold text-sm outline-none focus:border-blue-500"
            />
            <button
              type="submit"
              className="w-14 bg-slate-900 text-white rounded-2xl flex items-center justify-center"
            >
              <Check size={24} />
            </button>
          </form>
        )}
      </div>
    </div>
  );
};

export default QRScanner;
